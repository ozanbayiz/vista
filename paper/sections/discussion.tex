\section{Discussion}
\label{sec:discussion}

\paragraph{Implications for SAE-based debiasing.}
Our decomposition reveals that published SAE-based debiasing results~\citep{sasse2024debias, pach2025saes} may conflate reconstruction error with targeted feature effects when the SAE bottleneck is not controlled for. On \pg, passthrough accounts for 57\% of the total SDF suppression effect; on \qii, the same intervention produces a $24\pp$ \emph{increase} in demographic content. These results do not invalidate prior findings on classification benchmarks, where reconstruction error may affect the measured attribute differently, but they demonstrate that free-form generation tasks require passthrough baselines. We recommend that future work report passthrough and random suppression baselines alongside any SAE-based intervention result.

\paragraph{The structured bottleneck is not generic noise.}
An important nuance: the SAE bottleneck is not random degradation. Matched-magnitude Gaussian noise produces only $4\pp$ gender DCR change, while the SAE bottleneck produces $16\pp$. The SAE's sparse coding constraint systematically under-represents the demographic subspace because demographic attributes occupy a low-rank, linearly-encoded portion of the representation space---exactly the kind of information that top-$k$ sparsity tends to discard. This is consistent with our finding that LEACE (which removes a rank-1 gender subspace) drops VQA accuracy to chance: gender is concentrated in a small subspace that sparse reconstruction inadvertently disrupts.

In this sense, the SAE acts as an \emph{unintentional demographic filter}: it preferentially preserves coarse semantic content (object identity, scene layout) while losing fine-grained demographic attributes during sparse reconstruction. This filtering is a property of the interaction between the representation's geometry and the sparsity constraint, not a design choice. Whether this unintentional filtering should be considered a form of ``debiasing'' is partly a question of framing: it reduces demographic content, but without the interpretability guarantees that motivate SAE-based approaches. Our contribution is to quantify this component separately from the targeted component that does rely on feature identification.

\paragraph{Scope: output-layer vs.\ internal SAEs.}
Our experiments apply SAEs to the vision encoder's \emph{output} (the modal interface between VE and LM). Most mechanistic interpretability work applies SAEs to internal residual streams of transformers (e.g., intermediate ViT layers or LM residual streams). The bottleneck confound may be maximised at the VE output, where information density is highest and the LM is most sensitive to perturbation. Internal-layer SAEs modify representations that are further processed by subsequent transformer layers, which may partially compensate for reconstruction error---analogous to how residual connections help error correction in deep networks. We leave systematic internal-layer ablation to future work, noting that it requires not only retraining SAEs at each depth but also a hook mechanism that intercepts, reconstructs, and reinjects activations \emph{within} the VE forward pass, rather than at the modal interface. Future work should also examine whether the bottleneck confound extends to SAEs applied within the language model's residual stream, where the error correction capacity of subsequent LM layers may differ from that of VE layers.

\paragraph{Architecture-dependent bottleneck: a feature, not a bug?}
The cross-model comparison suggests a practical insight: VLMs whose language models default to neutral language (like \qii) are naturally robust to SAE reconstruction artifacts, while VLMs with strong demographic language priors (like \pg) are highly susceptible. If the goal is VLM debiasing, the bottleneck effect---while confounding for interpretability research---may itself be a useful mechanism. A carefully calibrated SAE bottleneck could serve as a simple, non-targeted debiasing tool, though at the cost of some general caption quality (BERTScore $\sim$0.93).

\paragraph{LEACE as a diagnostic tool.}
LEACE's contrasting behaviour across tasks (VQA to chance, captioning nearly unchanged on \pg) provides a diagnostic for how demographic information is accessed in different generation modes. When LEACE is effective on captioning (as on \qiii), it indicates a stronger linear component in the VE's demographic encoding that captioning depends on. When it is ineffective on captioning but effective on VQA (as on \pg), the information used for captioning is either encoded nonlinearly, distributed across token positions in a way the mean-pooled projection does not fully capture, or compensated for by language model priors. This VQA--captioning dissociation was not previously documented and motivates future work to disentangle VE-side encoding geometry from LM-side generation strategy.

\paragraph{Limitations.}
Our study has several limitations. (1) We evaluate only three VLMs, all in the 2--3B parameter range; larger models may exhibit different bottleneck characteristics. (2) FairFace consists of cropped, aligned face images where the face dominates the visual field; this represents the easiest case for vision encoder reconstruction. In complex scenes (e.g., COCO, Visual Genome) where faces are small or occluded, the bottleneck may manifest as hallucination rather than debiasing, and the interaction between reconstruction error and demographic content could differ substantially. (3) Our keyword DCR metric, while validated by LLM judges for gender, is unreliable for race; we address this limitation but cannot fully resolve it within the current evaluation framework. (4) Sample sizes, while larger than some prior work ($n{=}1{,}000$ for captioning, $n{=}200$ for VQA), may be insufficient to detect small interaction effects, and VQA results lack bootstrap CIs. (5) We do not evaluate on downstream fairness benchmarks (e.g., bias amplification scores), focusing instead on the mechanistic decomposition. (6) The cross-model comparison confounds SAE reconstruction quality with VLM architecture; the bottleneck may be absent on \qiii partly because its SAE has higher cosine similarity (0.975 vs.\ 0.945 for \pg), not solely due to architectural properties. Ablating reconstruction quality on a single model (e.g., via dictionary size variation or higher-fidelity SAE architectures such as Matryoshka SAEs~\citep{zaigrajew2025matryoshka}) would isolate this confound. (7) The LEACE projection is fit on mean-pooled features but applied per-token, which may incompletely erase spatially-varying concept information (see Appendix~\ref{app:details}).

\section{Conclusion}
\label{sec:conclusion}

We have shown that SAE-based interventions in vision-language models are subject to a substantial \emph{reconstruction-error confound}: the SAE's encode-decode process itself, independent of any feature modification, accounts for an architecture-dependent portion of reported debiasing effects. Through a systematic six-method decomposition across three VLMs, we separate the full intervention effect into generic noise ($\sim$4\pp), structured reconstruction error (0--16\pp depending on architecture), and targeted suppression ($\sim$12\pp). The reconstruction component scales monotonically with SAE quality, confirming it is a property of sparse coding rather than feature identification. On \qii, the same intervention produces the opposite effect entirely, demonstrating that architecture-dependent language generation strategies can amplify or invert reconstruction artifacts (Appendix~\ref{app:q2vl-qualitative}).

Our results do not invalidate SAE-based interpretability---targeted SDF suppression produces statistically significant effects beyond the reconstruction baseline on all tested models. However, they demonstrate that the magnitude of these effects has been substantially overstated in work that lacks passthrough controls. We recommend that future studies report passthrough and noise baselines, use LLM-based evaluation for racial content (where keyword metrics have $>$77\% false-positive rates), and validate across VLMs with different language generation strategies. LEACE provides a complementary, reconstruction-free baseline that reveals the linear structure of demographic encoding and the dissociation between VQA and captioning information pathways.
